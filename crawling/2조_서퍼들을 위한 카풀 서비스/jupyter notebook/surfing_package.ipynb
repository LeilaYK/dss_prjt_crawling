{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### surfing_package 설치 및 구동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 디렉토리 생성 및 package 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf surfing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p surfing/surfing\n",
    "!mkdir -p surfing/surfing/wsbfarm\n",
    "!mkdir -p surfing/surfing/surfx\n",
    "!touch surfing/setup.py\n",
    "!touch surfing/surfing/__init__.py\n",
    "!touch surfing/surfing/wsbfarm/__init__.py\n",
    "!touch surfing/surfing/surfx/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34msurfing\u001b[00m\r\n",
      "├── setup.py\r\n",
      "└── \u001b[01;34msurfing\u001b[00m\r\n",
      "    ├── __init__.py\r\n",
      "    ├── \u001b[01;34msurfx\u001b[00m\r\n",
      "    │   └── __init__.py\r\n",
      "    └── \u001b[01;34mwsbfarm\u001b[00m\r\n",
      "        └── __init__.py\r\n",
      "\r\n",
      "3 directories, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree surfing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wsbfarm 모듈 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing surfing/surfing/wsbfarm/Wsbfarm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile surfing/surfing/wsbfarm/Wsbfarm.py\n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "class Wsbfarm:\n",
    "    '''\n",
    "    서비스 설명 : WsbFarm으로부터 파도 데이터들을 가지고 오는 서비스입니다.\n",
    "    객체로 받아 클래스를 실행하세요. ex) wsb = Wsbfarm()\n",
    "    \n",
    "    - beach_list() : WsbFarm에 등록된 해변 리스트들을 불러오는 서비스입니다.\n",
    "    - login(email, pw): WsbFarm에 로그인 하는 메소드입니다. wsbfarm id, pw를 입력하세요\n",
    "    - get_wave_beach('원하는 해변 코드') : 원하는 해변의 10일치 파도 정보를 가지고 오는 서비스입니다.\n",
    "    - get_wave_data() : 모든 해변 (30개)의 10일치 파도 정보를 가지고 오는 서비스입니다. 불러온 데이터는 'wsbfarm.csv' 파일로 저장됩니다.\n",
    "    - get_wave_date(yyyymmdd) : 원하는 날짜의 해변들의 파도 정보를 가지고 오는 서비스입니다. (ex, 20200930)\n",
    "    - close() : 서비스를 종료하는 기능입니다.\n",
    "    '''\n",
    "    \n",
    "    # 생성자 함수\n",
    "    def __init__(self):\n",
    "        wsb_url = \"https://www.wsbfarm.com/wavecam/WaveCamList#video_list\"        \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"user-agent={}\".format(UserAgent().chrome))\n",
    "        options.add_argument(\"headless\")\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "        self.driver.implicitly_wait(1)\n",
    "        self.driver.get(wsb_url) \n",
    "        self.result_df = None\n",
    "        self.yyyymmdd = None\n",
    "    \n",
    "    # 해변 리스트 출력 메서드 : 중복 해변 제외한 30개 해변\n",
    "    def beach_list(self):\n",
    "        '''\n",
    "        WsbFarm에 등록된 해변 리스트들을 불러오는 서비스입니다.\n",
    "        '''\n",
    "        \n",
    "        url = \"https://www.wsbfarm.com/wavecam/WaveCamList\"\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        beach_lists = self.driver.find_elements_by_css_selector('#wrapper > div.index.main_content > div.main_content_inner.camList > div.swiper-container.gallery-top.swiper-container-initialized.swiper-container-horizontal.swiper-container-autoheight > ul > li.swiper-slide.swiper-slide-active > div > div > a')\n",
    "\n",
    "        beaches = []\n",
    "\n",
    "        for beach_list in beach_lists[:41]:\n",
    "            beach_eng = beach_list.get_attribute('data-urlid')\n",
    "            beach_kor = beach_list.find_element_by_css_selector('a > div.video-post-content.st01 > h4').text\n",
    "            beaches.append({'kor':beach_kor, 'eng':beach_eng})\n",
    "        \n",
    "        beach_list_df = pd.DataFrame(beaches)\n",
    "        self.beach_list_df = beach_list_df\n",
    "        self.beach_list_df = beach_list_df.loc[~beach_list_df['kor'].str.contains('B') & ~beach_list_df['kor'].str.contains('C')]\n",
    "        self.beach_list_df.reset_index(inplace=True, drop=True)\n",
    "        return self.beach_list_df\n",
    "    \n",
    "    # 로그인\n",
    "    def login(self, email, pw):\n",
    "        '''\n",
    "        WsbFarm에 로그인 하는 메소드입니다.\n",
    "        login(wsbfarm email, wsbfarm pw) 와 같이 입력하세요.\n",
    "        '''\n",
    "        \n",
    "        self.email = email\n",
    "        self.pw = pw\n",
    "        self.driver.find_element_by_css_selector('#main_header > header > div.head_user > button:nth-child(4)').click()\n",
    "        time.sleep(3)\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"userEmail\"]').send_keys(email)\n",
    "        time.sleep(1)\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"password\"]').send_keys(pw)\n",
    "        time.sleep(1)\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"wrapper\"]/div[3]/div/div/form/fieldset/div[1]/button').click()\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 3).until(EC.alert_is_present())\n",
    "            alert = self.driver.switch_to.alert\n",
    "            alert.accept()\n",
    "            print(\"Login Error!!!\")\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            print(\"Login Sucessful!!!\")\n",
    "        \n",
    "    # 특정 해변 상세정보 크롤링\n",
    "    def get_wave_beach(self, beach_eng):\n",
    "        '''\n",
    "        특정 해변의 상세정보를 크롤링하는 메소드입니다. 원하는 해변의 파도가 가장 높을 때의 시간, 바람, 온도 등을 표시합니다.\n",
    "        get_wave_beach(원하는 해변의 코드) 를 입력하세요.\n",
    "        '''\n",
    "        \n",
    "        self.beach_eng = beach_eng\n",
    "        url = \"https://www.wsbfarm.com/wavecam/WaveCamView?beach={}\".format(beach_eng)\n",
    "        self.driver.get(url)\n",
    "        self.driver.implicitly_wait(1)\n",
    "        # 파도 정보는 오늘 기준 10일치 데이터만 제공됨\n",
    "        # y좌표값 가져오기\n",
    "        yaxis = []\n",
    "        wave_data = []\n",
    "        i = 0\n",
    "        try:\n",
    "            while i < 10:\n",
    "                today = datetime.date.today()\n",
    "                sdate = today + datetime.timedelta(days = i)\n",
    "                sdate = sdate.strftime('%Y%m%d')\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # 로딩을 위해 우선 스크롤 내려주고\n",
    "                axis = self.driver.find_element_by_css_selector('.beachData[data-date=\"{}\"'.format(sdate)).location\n",
    "                yaxis.append({'date':sdate, 'location':axis['y']})\n",
    "                for j in range(1, 7):\n",
    "                    time_str = self.driver.find_element_by_css_selector('.beachData[data-date=\"{}\"] > table > tbody > tr:nth-child({}) > td:nth-child({})'.format(sdate, j, 1)).text\n",
    "                    wind = self.driver.find_element_by_css_selector('.beachData[data-date=\"{}\"] > table > tbody > tr:nth-child({}) > td:nth-child({})'.format(sdate, j, 2)).text\n",
    "                    temp = self.driver.find_element_by_css_selector('.beachData[data-date=\"{}\"] > table > tbody > tr:nth-child({}) > td:nth-child({})'.format(sdate, j, 3)).text.split('o')[0]\n",
    "                    wave = self.driver.find_element_by_css_selector('.beachData[data-date=\"{}\"] > table > tbody > tr:nth-child({}) > td:nth-child({})'.format(sdate, j, 4)).text.replace('\\n', ' & ').split('m')[0]\n",
    "                    wave_tide = self.driver.find_element_by_css_selector('.beachData[data-date=\"{}\"] > table > tbody > tr:nth-child({}) > td:nth-child({})'.format(sdate, j, 5)).text.split('m')[0]\n",
    "                    wave_data.append({\"date\": sdate, \"time\": time_str, \"wind\": wind, \"temp\": temp, \"wave\": float(wave), \"wave_tide\": float(wave_tide)})\n",
    "                i += 1\n",
    "                wave_df = pd.DataFrame(wave_data)\n",
    "                wave_df = wave_df[(wave_df['time'] != '오후 09') & (wave_df['time'] != '오전 12') & (wave_df['time'] != '오전 03')]\n",
    "                wave_df = wave_df.sort_values(['date', 'wave'])\n",
    "                wave_df = wave_df.groupby('date').tail(1)\n",
    "            # 위에서 구한 y좌표값으로 10일치 파도 요약정보 불러오기\n",
    "            wave_summary = []\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            for i in range(10):\n",
    "                self.driver.execute_script(\"window.scrollTo(0,{});\".format(yaxis[i]['location']))\n",
    "                time.sleep(0.5)\n",
    "                self.driver.execute_script(\"window.scrollTo(0,{});\".format(yaxis[i]['location']-10))\n",
    "                time.sleep(0.5)\n",
    "                summary = self.driver.find_element_by_css_selector('#con1 > div.beachToday.p_todayWaveinfo.fix.p_{} > div.wave'.format(yaxis[i]['date'])).text.split('오늘의 파도')[1].strip().replace(\"\\n\", \". \")\n",
    "                time.sleep(1)\n",
    "                wave_summary.append({'eng':beach_eng, 'date':yaxis[i]['date'], 'summary':summary})\n",
    "            summary_df = pd.DataFrame(wave_summary)\n",
    "            # 두개 데이터프레임 merge 시키기\n",
    "            self.result_df = summary_df.merge(wave_df, on='date')\n",
    "            return self.result_df\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 모든 해변에 대한 정보 가져오기\n",
    "    def get_wave_data(self):\n",
    "        '''\n",
    "        모든 해변에 대한 정보들을 가지고 오는 메소드입니다.\n",
    "        get_wave_data() 를 실행하세요.\n",
    "        '''\n",
    "        dfs = []            \n",
    "        for beach_eng in self.beach_list_df['eng']:\n",
    "            print(\"beach:{} crawling ...\".format(beach_eng))\n",
    "            self.beach_eng = beach_eng\n",
    "            df = self.get_wave_beach(beach_eng)\n",
    "            dfs.append(df)\n",
    "        self.result_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "        \n",
    "        if not os.path.isfile('wsbfarm.csv'): # if file does not exist \n",
    "            self.result_df.to_csv('wsbfarm.csv', index=False, encoding='utf-8')\n",
    "        else: # else it exists so append without writing the header\n",
    "            self.result_df.to_csv('wsbfarm.csv', mode='a', header=False, index=False, encoding='utf-8')\n",
    "        print(\"WSBfarm CSV saved!\")\n",
    "        \n",
    "    # 특정 날짜에 대한 파도 데이터 보기\n",
    "    def get_wave_date(self, yyyymmdd):\n",
    "        '''\n",
    "        특정 날짜에 대한 해변들의 파도 데이터를 가지고 오는 메소드입니다.\n",
    "        get_wave_date(20200920)와 같이 입력하세요.\n",
    "        '''\n",
    "        self.yyyymmdd = yyyymmdd\n",
    "        today = datetime.date.today()\n",
    "        crawling_date = today + datetime.timedelta(days = 10)\n",
    "        if int(yyyymmdd) < int(crawling_date.strftime('%Y%m%d')): # 파도 데이터는 10일치만 제공함 \n",
    "            # 해변, 날짜, 시간대가 같은 경우 중복으로 여겨 가장 최근 정보만 남기고 drop\n",
    "            df = pd.read_csv('wsbfarm.csv')\n",
    "            df.drop_duplicates(subset=['eng', 'date', 'time'], keep='last', inplace=True) \n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "            # 데이터프레임 정리해주기\n",
    "            self.result_df = df[df['date'] == yyyymmdd]\n",
    "            self.result_df.reset_index(inplace=True, drop=True)\n",
    "            self.result_df = self.result_df.merge(self.beach_list_df, on='eng')\n",
    "            self.result_df.drop(columns=['date', 'eng'], inplace=True)\n",
    "            self.result_df.rename(columns={\"kor\":\"beach\", \"wave\":\"max_wave\"}, inplace=True)\n",
    "            self.result_df = self.result_df[['beach', 'summary', \"time\", \"wind\", \"temp\", \"max_wave\", \"wave_tide\"]]\n",
    "            self.result_df.sort_values(by=['max_wave', 'beach'], ascending=False, inplace=True) # 파도가 높은순으로 정렬\n",
    "            self.result_df.reset_index(inplace=True, drop=True)\n",
    "            return self.result_df\n",
    "        else:\n",
    "            print(\"파도 데이터는 {}까지 데이터만 제공합니다. 다른 날짜를 입력해주세요\".format((today + datetime.timedelta(days = 9)).strftime('%Y%m%d')))\n",
    "    \n",
    "    # 종료\n",
    "    def close(self):\n",
    "        '''\n",
    "        프로그램을 종료하는 메소드입니다.\n",
    "        wsb.close()를 입력하세요.\n",
    "        '''\n",
    "        self.driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### surfx 모듈 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing surfing/surfing/surfx/Surfx.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile surfing/surfing/surfx/Surfx.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "class Surfx:\n",
    "    # 생성자\n",
    "    def __init__(self):\n",
    "        url = 'https://m.cafe.naver.com/surfx'\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.implicitly_wait(3)\n",
    "        self.driver.get(url)\n",
    "    \n",
    "    # 로그인\n",
    "    def login(self, id, pw):\n",
    "        self.id = id\n",
    "        self.pw = pw\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"hd\"]/div/div[4]/a').click() # 사이드 메뉴 클릭\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"sideMenuContainer\"]/header/div/div/div/a[2]').click() # 로그인 클릭\n",
    "        input_js = 'document.getElementById(\"id\").value = \"{}\";document.getElementById(\"pw\").value = \"{}\";'.format(self.id, self.pw)\n",
    "        time.sleep(random.uniform(1,3)) # 자동화탐지를 우회 하기 위한 delay\n",
    "        self.driver.execute_script(input_js)\n",
    "        time.sleep(random.uniform(1,3)) # 자동화탐지를 우회 하기 위한 delay\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"log.login\"]').click() # 로그인 버튼 클릭\n",
    "        print(\"Done\")\n",
    "        \n",
    "    def __get_list(self):  \n",
    "        self.driver.find_element_by_xpath('//*[@id=\"hd\"]/div/div[4]/a').click() # 사이드 메뉴 클릭\n",
    "        self.driver.find_element_by_xpath('//*[@id=\"sideMenuContainer\"]/div/div[2]/div[1]/div/ul/li/div/a[1]/span/span').click() # 카풀 게시판 클릭\n",
    "        elements = self.driver.find_elements_by_xpath('//*[@id=\"ct\"]/div/ul/li') # 게시판 글 갯수 60개\n",
    "\n",
    "        links = []  # 게시글 링크\n",
    "        for element in elements:\n",
    "            link = element.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "            links.append(link)\n",
    "        return links\n",
    "    \n",
    "    def get_data(self):\n",
    "        datas = []\n",
    "        links = self.__get_list()\n",
    "        for i in range(len(links)):\n",
    "            try:\n",
    "                self.driver.get(links[i])\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 카풀 정보 가져오기\n",
    "                dom = BeautifulSoup(self.driver.page_source , 'html.parser')\n",
    "                title = dom.select_one('div.post_title > h2').text.strip()\n",
    "                nick = dom.select_one('div.user_wrap > div.info > a.nick > span > span').text\n",
    "                post_date = dom.select_one('div.user_wrap > div.info > span.date.font_l').text.split('작성일')[1]\n",
    "                content = dom.select_one('#postContent').text.strip().split(' 투표는 표시되지 않습니다.')[0].replace(\"\\n\", \"\")\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 작성자 정보 가져오기\n",
    "                self.driver.find_element_by_xpath('//*[@id=\"ct\"]/div[1]/div/div[2]/div[1]/a[1]/span').click()\n",
    "                time.sleep(1)\n",
    "                dom = BeautifulSoup(self.driver.page_source , 'html.parser')\n",
    "                nick_info = dom.select_one('#memberInfo > div > div.info_profile > div > div.desc').text.split(' ')\n",
    "                cafe_level = nick_info[0].split('등급')[1].split('방문')[0]\n",
    "                cafe_visit = nick_info[1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            print(i)\n",
    "            datas.append({'title':title, 'nick':nick, 'level':cafe_level, 'visit':cafe_visit, 'post_date':post_date, 'content':content, 'link':links[i]})\n",
    "\n",
    "        self.df = pd.DataFrame(datas)\n",
    "\n",
    "        if not os.path.isfile('surfx.csv'): # if file does not exist \n",
    "            self.df.to_csv('surfx.csv', index=False, encoding='utf-8-sig')\n",
    "        else: # else it exists so append without writing the header\n",
    "            self.df.to_csv('surfx.csv', encoding='utf-8-sig', mode='a', header=False, index=False)\n",
    "        print(\"CSV saved!\")\n",
    "    \n",
    "    def get_carpool(self, date_data):\n",
    "        self.date_data = date_data\n",
    "        \n",
    "        # csv 가져와서 중복데이터 삭제\n",
    "        df = pd.read_csv('surfx.csv')\n",
    "        df.drop_duplicates(subset=['title', 'nick'], keep='first', inplace=True) # 제목과 작성자 닉네임이 같을 경우 중복으로 여겨 제외시킴\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        # [카풀제공] 데이터만 불러오기\n",
    "        idx = []\n",
    "        for i in range(len(df)):\n",
    "            idx.append('[카풀제공]' in df['title'][i])\n",
    "        surfx_df = df[idx]\n",
    "        surfx_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "        # 카풀 제공 날짜 찾기\n",
    "        dates = []\n",
    "\n",
    "        for i in range(len(surfx_df)):\n",
    "            if '오늘' in surfx_df['title'][i]:\n",
    "                p_date = surfx_df['post_date'][i].replace(\".\", \"\").split(\" \")[0] # 작성일 불러오기\n",
    "                p_date = datetime.datetime(year=int(p_date[:4]), month=int(p_date[4:6]), day=int(p_date[6:8])) # 불러온 작성일을 datetime형식에 넣어주기\n",
    "                mmdd = p_date.strftime('%y%m%d') # 월일만 표시하기\n",
    "            elif '내일' in surfx_df['title'][i]:\n",
    "                p_date = surfx_df['post_date'][i].replace(\".\", \"\").split(\" \")[0] # 작성일 불러오기\n",
    "                p_date = datetime.datetime(year=int(p_date[:4]), month=int(p_date[4:6]), day=int(p_date[6:8])) # 불러온 작성일을 datetime형식에 넣어주기\n",
    "                tomorrow = p_date + datetime.timedelta(days = 1) # 하루 더해주고\n",
    "                tomorrow = tomorrow.strftime('%y%m%d') # 월일만 표시하기\n",
    "                mmdd = tomorrow\n",
    "            elif '내일' not in surfx_df['title'][i]:\n",
    "                try: # 어떤 형식으로든 월도 함께 적어준 경우\n",
    "                    d_data = re.search('[0-9]{1,2}일|/[0-9]{1,2}|\\.[0-9]{1,2}', surfx_df['title'][i]).group() # 일 정보 불러오기\n",
    "                    d_data = int(re.sub(\"[^0-9]\", \"\", d_data)) # 숫자만 불러오기\n",
    "                    m_data = re.search('[0-9]{1,2}월|[0-9]{1,2}/|[0-9]{1,2}\\.', surfx_df['title'][i]).group() # 월 정보 불러오기\n",
    "                    m_data = int(re.sub(\"[^0-9]\", \"\", m_data)) # 숫자만 불러오기\n",
    "                    mmdd = datetime.datetime(year=2020, month=m_data, day=d_data) # 찾아낸 월 & 일 정보를 datetime형식에 넣어주기\n",
    "                    mmdd = mmdd.strftime('%y%m%d') # 월일만 표시하기\n",
    "                except: #월은 생략하고 일만 적어준 경우\n",
    "                    p_date = surfx_df['post_date'][i].replace(\".\", \"\").split(\" \")[0] # 작성일 불러오기\n",
    "                    p_date_day = int(p_date[6:8]) # 작성일 중 일 데이터만 불러오기\n",
    "                    if p_date_day > d_data: # 작성일이 카풀일보다 큰 경우 예) 작성일: 9월27일, 카풀일: 10월1일\n",
    "                        m_data = int(p_date[4:6]) + 1 # 카풀월은 작성월의 다음월이기 때문에 +1 해줌 \n",
    "                    else: #작성일이 카풀일보다 작거나 같은 경우 예) 작성일: 9월3일, 카풀일: 9월5일\n",
    "                        m_data = int(p_date[4:6]) # 카풀월은 작성월과 동일\n",
    "                    mmdd = datetime.datetime(year=2020, month=m_data, day=d_data) # 찾아낸 월 & 일 정보를 datetime형식에 넣어주기\n",
    "                    mmdd = mmdd.strftime('%y%m%d')\n",
    "            else:\n",
    "                mmdd = \"???\"\n",
    "\n",
    "            dates.append(mmdd)\n",
    "        \n",
    "        surfx_df['carpool'] = dates # carpool 날짜 추가하기\n",
    "        surfx_df = surfx_df[['carpool', 'title', 'nick', 'level', 'visit', 'post_date', 'content', 'link']] # 컬럼 순서 정리\n",
    "        result = surfx_df[surfx_df['carpool'] == str(date_data)] # 검색한 날짜 데이터만 가져오기\n",
    "        result.drop(columns=['carpool'], inplace=True)\n",
    "        result.reset_index(inplace=True, drop=True)\n",
    "        if result.empty:\n",
    "            result = '검색하신 날짜에 카풀을 제공하지 않습니다'\n",
    "        return result\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34msurfing\u001b[00m\r\n",
      "├── setup.py\r\n",
      "└── \u001b[01;34msurfing\u001b[00m\r\n",
      "    ├── __init__.py\r\n",
      "    ├── \u001b[01;34msurfx\u001b[00m\r\n",
      "    │   ├── Surfx.py\r\n",
      "    │   └── __init__.py\r\n",
      "    └── \u001b[01;34mwsbfarm\u001b[00m\r\n",
      "        ├── Wsbfarm.py\r\n",
      "        └── __init__.py\r\n",
      "\r\n",
      "3 directories, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree surfing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting surfing/surfing/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile surfing/surfing/__init__.py\n",
    "\n",
    "from .wsbfarm.Wsbfarm import *  # .: 현재 디렉토리     .(상대경로) , /(절대경로)\n",
    "from .surfx.Surfx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting surfing/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile surfing/setup.py\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name = \"surpool\",\n",
    "    version=\"0.0.1\",\n",
    "    author=\"dss14 JinWonGi\",\n",
    "    author_email=\"ansm204@icloud.com\",\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup.py \u001b[34msurfing\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls surfing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. package 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/stevenkim/Documents/project/03_crawling/surfing\n",
      "Installing collected packages: surfing\n",
      "  Running setup.py develop for surfing\n",
      "Successfully installed surfing\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e surfing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surfing                            0.0.1               /Users/stevenkim/Documents/project/03_crawling/surfing\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34msurfing\u001b[00m\r\n",
      "├── setup.py\r\n",
      "├── \u001b[01;34msurfing\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── \u001b[01;34msurfx\u001b[00m\r\n",
      "│   │   ├── Surfx.py\r\n",
      "│   │   └── __init__.py\r\n",
      "│   └── \u001b[01;34mwsbfarm\u001b[00m\r\n",
      "│       ├── Wsbfarm.py\r\n",
      "│       └── __init__.py\r\n",
      "└── \u001b[01;34msurfing.egg-info\u001b[00m\r\n",
      "    ├── PKG-INFO\r\n",
      "    ├── SOURCES.txt\r\n",
      "    ├── dependency_links.txt\r\n",
      "    └── top_level.txt\r\n",
      "\r\n",
      "4 directories, 10 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree surfing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. package 구동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surfing.surfing.wsbfarm import Wsbfarm as ws\n",
    "from surfing.surfing.surfx import Surfx as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wsbfarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb = ws.Wsbfarm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kor</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>고성 송지호해변</td>\n",
       "      <td>SJH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>고성 천진해변</td>\n",
       "      <td>GCJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>속초 속초해변</td>\n",
       "      <td>SCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>양양 물치해변</td>\n",
       "      <td>MUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>양양 설악해변</td>\n",
       "      <td>YSK1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>양양 기사문해변A</td>\n",
       "      <td>GSM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>양양 동산해변</td>\n",
       "      <td>DS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>양양 죽도해변A</td>\n",
       "      <td>JD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>양양 인구해변</td>\n",
       "      <td>IJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>양양 갯마을해변</td>\n",
       "      <td>GMU1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>양양 남애3리해변A</td>\n",
       "      <td>NA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>양양 남애1리해변</td>\n",
       "      <td>YNA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>강릉 주문진해변</td>\n",
       "      <td>GJMJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>강릉 사천해변</td>\n",
       "      <td>SC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>강릉 금진해변A</td>\n",
       "      <td>GJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>동해 대진해변A</td>\n",
       "      <td>DJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>삼척 용화해변</td>\n",
       "      <td>YWH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>포항 신항만해변A</td>\n",
       "      <td>SHM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>울산 진하해변</td>\n",
       "      <td>JH1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>부산 송정해변A</td>\n",
       "      <td>SJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>부산 송정해변D</td>\n",
       "      <td>SJ4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>부산 다대포해변</td>\n",
       "      <td>DDP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>태안 만리포해변A</td>\n",
       "      <td>MLP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>제주 중문해변[점검중]</td>\n",
       "      <td>JM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>제주 중문 듀크포인트</td>\n",
       "      <td>JM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>제주 사계해변</td>\n",
       "      <td>JSG1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>제주 곽지해변</td>\n",
       "      <td>JGJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>제주 이호테우해변</td>\n",
       "      <td>JIT1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>제주 월정해변</td>\n",
       "      <td>WJ1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>제주 쇠소깍해변[점검중]</td>\n",
       "      <td>SKK1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              kor    eng\n",
       "0        고성 송지호해변   SJH1\n",
       "1         고성 천진해변   GCJ1\n",
       "2         속초 속초해변   SCC1\n",
       "3         양양 물치해변    MUL\n",
       "4         양양 설악해변   YSK1\n",
       "5       양양 기사문해변A   GSM1\n",
       "6         양양 동산해변    DS1\n",
       "7        양양 죽도해변A    JD1\n",
       "8         양양 인구해변    IJ1\n",
       "9        양양 갯마을해변   GMU1\n",
       "10     양양 남애3리해변A    NA1\n",
       "11      양양 남애1리해변   YNA1\n",
       "12       강릉 주문진해변  GJMJ1\n",
       "13        강릉 사천해변    SC1\n",
       "14       강릉 금진해변A    GJ1\n",
       "15       동해 대진해변A    DJ1\n",
       "16        삼척 용화해변   YWH1\n",
       "17      포항 신항만해변A   SHM1\n",
       "18        울산 진하해변    JH1\n",
       "19       부산 송정해변A    SJ1\n",
       "20       부산 송정해변D    SJ4\n",
       "21       부산 다대포해변   DDP1\n",
       "22      태안 만리포해변A   MLP1\n",
       "23   제주 중문해변[점검중]    JM1\n",
       "24    제주 중문 듀크포인트    JM2\n",
       "25        제주 사계해변   JSG1\n",
       "26        제주 곽지해변   JGJ1\n",
       "27      제주 이호테우해변   JIT1\n",
       "28        제주 월정해변    WJ1\n",
       "29  제주 쇠소깍해변[점검중]   SKK1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb.beach_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Sucessful!!!\n"
     ]
    }
   ],
   "source": [
    "wsb.login('wsb_email', 'wsb_pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb.get_wave_beach('SJ1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach:SJH1 crawling ...\n",
      "beach:GCJ1 crawling ...\n",
      "beach:SCC1 crawling ...\n",
      "beach:MUL crawling ...\n",
      "beach:YSK1 crawling ...\n",
      "beach:GSM1 crawling ...\n",
      "beach:DS1 crawling ...\n",
      "beach:JD1 crawling ...\n",
      "beach:IJ1 crawling ...\n",
      "beach:GMU1 crawling ...\n",
      "beach:NA1 crawling ...\n",
      "beach:YNA1 crawling ...\n",
      "beach:GJMJ1 crawling ...\n",
      "beach:SC1 crawling ...\n",
      "beach:GJ1 crawling ...\n",
      "beach:DJ1 crawling ...\n",
      "beach:YWH1 crawling ...\n",
      "beach:SHM1 crawling ...\n",
      "beach:JH1 crawling ...\n",
      "beach:SJ1 crawling ...\n",
      "beach:SJ4 crawling ...\n",
      "beach:DDP1 crawling ...\n",
      "beach:MLP1 crawling ...\n",
      "beach:JM1 crawling ...\n",
      "beach:JM2 crawling ...\n",
      "beach:JSG1 crawling ...\n",
      "beach:JGJ1 crawling ...\n",
      "beach:JIT1 crawling ...\n",
      "beach:WJ1 crawling ...\n",
      "beach:SKK1 crawling ...\n",
      "WSBfarm CSV saved!\n"
     ]
    }
   ],
   "source": [
    "wsb.get_wave_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>time</th>\n",
       "      <th>wind</th>\n",
       "      <th>temp</th>\n",
       "      <th>wave</th>\n",
       "      <th>wave_tide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SJH1</td>\n",
       "      <td>20200925</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>3.4m/s</td>\n",
       "      <td>18</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SJH1</td>\n",
       "      <td>20200926</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>4.4m/s</td>\n",
       "      <td>18</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SJH1</td>\n",
       "      <td>20200927</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오전 06</td>\n",
       "      <td>2.3m/s</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SJH1</td>\n",
       "      <td>20200928</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 12</td>\n",
       "      <td>2.6m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SJH1</td>\n",
       "      <td>20200929</td>\n",
       "      <td>중급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 허리~어깨 높이...</td>\n",
       "      <td>오전 06</td>\n",
       "      <td>1.7m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>SKK1</td>\n",
       "      <td>20200930</td>\n",
       "      <td>역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>3.0m/s</td>\n",
       "      <td>24</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>SKK1</td>\n",
       "      <td>20201001</td>\n",
       "      <td>역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...</td>\n",
       "      <td>오전 09</td>\n",
       "      <td>1.9m/s</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>SKK1</td>\n",
       "      <td>20201002</td>\n",
       "      <td>역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...</td>\n",
       "      <td>오전 09</td>\n",
       "      <td>4.3m/s</td>\n",
       "      <td>21</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>SKK1</td>\n",
       "      <td>20201003</td>\n",
       "      <td>역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...</td>\n",
       "      <td>오전 09</td>\n",
       "      <td>1.6m/s</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>SKK1</td>\n",
       "      <td>20201004</td>\n",
       "      <td>패들연습 하세요~. 바다에서 바라 본 해변의 풍경은 언제나 진리에요~</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>4.4m/s</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      eng      date                                            summary   time  \\\n",
       "0    SJH1  20200925  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "1    SJH1  20200926  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 03   \n",
       "2    SJH1  20200927  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오전 06   \n",
       "3    SJH1  20200928  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 12   \n",
       "4    SJH1  20200929  중급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 허리~어깨 높이...  오전 06   \n",
       "..    ...       ...                                                ...    ...   \n",
       "515  SKK1  20200930  역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...  오후 03   \n",
       "516  SKK1  20201001  역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...  오전 09   \n",
       "517  SKK1  20201002  역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...  오전 09   \n",
       "518  SKK1  20201003  역스웰에는 파도를 예측하기 힘들어요. 깜짝 파도를 대비해 주기적으로 파도웹캠을 확인...  오전 09   \n",
       "519  SKK1  20201004             패들연습 하세요~. 바다에서 바라 본 해변의 풍경은 언제나 진리에요~  오후 03   \n",
       "\n",
       "       wind  temp  wave  wave_tide  \n",
       "0    3.4m/s    18   2.4       0.13  \n",
       "1    4.4m/s    18   2.8       0.21  \n",
       "2    2.3m/s    15   2.5       0.28  \n",
       "3    2.6m/s    19   1.7       0.36  \n",
       "4    1.7m/s    19   1.2       0.25  \n",
       "..      ...   ...   ...        ...  \n",
       "515  3.0m/s    24   0.5       0.75  \n",
       "516  1.9m/s    20   1.0       2.63  \n",
       "517  4.3m/s    21   0.5       2.70  \n",
       "518  1.6m/s    20   0.4       2.73  \n",
       "519  4.4m/s    24   0.0       1.32  \n",
       "\n",
       "[520 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wsbfarm.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beach</th>\n",
       "      <th>summary</th>\n",
       "      <th>time</th>\n",
       "      <th>wind</th>\n",
       "      <th>temp</th>\n",
       "      <th>max_wave</th>\n",
       "      <th>wave_tide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>고성 송지호해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>3.4m/s</td>\n",
       "      <td>18</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼척 용화해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>3.2m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>동해 대진해변A</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.6m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>속초 속초해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.0m/s</td>\n",
       "      <td>18</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고성 천진해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.0m/s</td>\n",
       "      <td>18</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>포항 신항만해변A</td>\n",
       "      <td>상급자 서핑 가능해요. 중급 및 상급자 서핑은 가능하지만 파도면이 좋지 않을 것으로...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>4.4m/s</td>\n",
       "      <td>20</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>양양 설악해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>2.6m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>양양 물치해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>2.6m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>강릉 사천해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>1.5m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>강릉 주문진해변</td>\n",
       "      <td>상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>1.8m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>양양 죽도해변A</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.7m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>양양 인구해변</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.7m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>양양 남애3리해변A</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.7m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>양양 남애1리해변</td>\n",
       "      <td>중급자 서핑하기 적당해요. 다소 약한 온쇼어를 동반한 허리~어깨 높이 파도가 예상돼요</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.7m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>양양 기사문해변A</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.8m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>양양 갯마을해변</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.7m/s</td>\n",
       "      <td>17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>강릉 금진해변A</td>\n",
       "      <td>상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>4.3m/s</td>\n",
       "      <td>18</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>울산 진하해변</td>\n",
       "      <td>중급자 서핑 가능해요. 초급 및 중급자 서핑은 가능하지만 파도면이 고르지 않을 것으...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>7.6m/s</td>\n",
       "      <td>20</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>부산 송정해변D</td>\n",
       "      <td>중급자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 허리~어깨 높이 파...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>5.0m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>부산 송정해변A</td>\n",
       "      <td>중급자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 허리~어깨 높이 파...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>5.0m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>제주 월정해변</td>\n",
       "      <td>중급자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 허리~어깨 높이 파...</td>\n",
       "      <td>오전 06</td>\n",
       "      <td>3.5m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>제주 곽지해변</td>\n",
       "      <td>초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.5m/s</td>\n",
       "      <td>22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>부산 다대포해변</td>\n",
       "      <td>패들연습 하세요. 호수같은 바다의 잔잔함을 느껴봐요</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>5.4m/s</td>\n",
       "      <td>21</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>제주 중문해변[점검중]</td>\n",
       "      <td>초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...</td>\n",
       "      <td>오전 06</td>\n",
       "      <td>2.0m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>제주 중문 듀크포인트</td>\n",
       "      <td>초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...</td>\n",
       "      <td>오전 06</td>\n",
       "      <td>2.0m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>제주 이호테우해변</td>\n",
       "      <td>초보자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 무릎~허리 높이...</td>\n",
       "      <td>오후 06</td>\n",
       "      <td>2.6m/s</td>\n",
       "      <td>22</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>제주 쇠소깍해변[점검중]</td>\n",
       "      <td>초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...</td>\n",
       "      <td>오전 06</td>\n",
       "      <td>2.0m/s</td>\n",
       "      <td>19</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>태안 만리포해변A</td>\n",
       "      <td>패들연습 하세요. 호수같은 바다의 잔잔함을 느껴봐요</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>3.8m/s</td>\n",
       "      <td>24</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>제주 사계해변</td>\n",
       "      <td>패들연습 하세요. 호수같은 바다의 잔잔함을 느껴봐요</td>\n",
       "      <td>오후 03</td>\n",
       "      <td>4.1m/s</td>\n",
       "      <td>24</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            beach                                            summary   time  \\\n",
       "0        고성 송지호해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "1         삼척 용화해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "2        동해 대진해변A  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "3         속초 속초해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "4         고성 천진해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "5       포항 신항만해변A  상급자 서핑 가능해요. 중급 및 상급자 서핑은 가능하지만 파도면이 좋지 않을 것으로...  오후 06   \n",
       "6         양양 설악해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 03   \n",
       "7         양양 물치해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 03   \n",
       "8         강릉 사천해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "9        강릉 주문진해변  상급자 이상 서핑 가능해요. 서핑 영화 '폭풍속으로'의 마지막 장면을 기억하시나요?...  오후 06   \n",
       "10       양양 죽도해변A  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 06   \n",
       "11        양양 인구해변  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 06   \n",
       "12     양양 남애3리해변A  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 06   \n",
       "13      양양 남애1리해변    중급자 서핑하기 적당해요. 다소 약한 온쇼어를 동반한 허리~어깨 높이 파도가 예상돼요  오후 06   \n",
       "14      양양 기사문해변A  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 06   \n",
       "15       양양 갯마을해변  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 06   \n",
       "16       강릉 금진해변A  상급자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 성인 평균키 높...  오후 03   \n",
       "17        울산 진하해변  중급자 서핑 가능해요. 초급 및 중급자 서핑은 가능하지만 파도면이 고르지 않을 것으...  오후 06   \n",
       "18       부산 송정해변D  중급자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 허리~어깨 높이 파...  오후 06   \n",
       "19       부산 송정해변A  중급자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 허리~어깨 높이 파...  오후 06   \n",
       "20        제주 월정해변  중급자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 허리~어깨 높이 파...  오전 06   \n",
       "21        제주 곽지해변  초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...  오후 06   \n",
       "22       부산 다대포해변                       패들연습 하세요. 호수같은 바다의 잔잔함을 느껴봐요  오후 06   \n",
       "23   제주 중문해변[점검중]  초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...  오전 06   \n",
       "24    제주 중문 듀크포인트  초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...  오전 06   \n",
       "25      제주 이호테우해변  초보자 서핑하기 적당해요. 바다에서 해변으로 다소 약한 바람이 불며 무릎~허리 높이...  오후 06   \n",
       "26  제주 쇠소깍해변[점검중]  초보자 서핑하기 매우 좋아요. 해변에서 바다로 약한 바람이 불며 무릎~허리 높이 파...  오전 06   \n",
       "27      태안 만리포해변A                       패들연습 하세요. 호수같은 바다의 잔잔함을 느껴봐요  오후 03   \n",
       "28        제주 사계해변                       패들연습 하세요. 호수같은 바다의 잔잔함을 느껴봐요  오후 03   \n",
       "\n",
       "      wind  temp  max_wave  wave_tide  \n",
       "0   3.4m/s    18       2.4       0.13  \n",
       "1   3.2m/s    19       2.3       0.14  \n",
       "2   2.6m/s    17       2.3       0.14  \n",
       "3   2.0m/s    18       2.2       0.13  \n",
       "4   2.0m/s    18       2.2       0.13  \n",
       "5   4.4m/s    20       2.1       0.30  \n",
       "6   2.6m/s    19       2.1       0.17  \n",
       "7   2.6m/s    19       2.1       0.17  \n",
       "8   1.5m/s    17       2.0       0.14  \n",
       "9   1.8m/s    17       1.9       0.13  \n",
       "10  2.7m/s    17       1.8       0.13  \n",
       "11  2.7m/s    17       1.8       0.13  \n",
       "12  2.7m/s    17       1.8       0.13  \n",
       "13  2.7m/s    17       1.8       0.13  \n",
       "14  2.8m/s    17       1.8       0.13  \n",
       "15  2.7m/s    17       1.8       0.13  \n",
       "16  4.3m/s    18       1.8       0.17  \n",
       "17  7.6m/s    20       1.4       0.30  \n",
       "18  5.0m/s    19       1.4       0.88  \n",
       "19  5.0m/s    19       1.4       0.88  \n",
       "20  3.5m/s    19       1.0       1.87  \n",
       "21  2.5m/s    22       0.5       2.48  \n",
       "22  5.4m/s    21       0.5       0.88  \n",
       "23  2.0m/s    19       0.4       1.62  \n",
       "24  2.0m/s    19       0.4       1.62  \n",
       "25  2.6m/s    22       0.4       2.48  \n",
       "26  2.0m/s    19       0.4       1.62  \n",
       "27  3.8m/s    24       0.3       2.01  \n",
       "28  4.1m/s    24       0.2       1.69  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb.get_wave_date(20200925)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### surfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfx = sf.Surfx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 로그인하기\n",
    "surfx.login('naver_id', 'naver_pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "CSV saved!\n"
     ]
    }
   ],
   "source": [
    "# 카풀 게시글 크롤링해서 csv로 저장\n",
    "surfx.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>nick</th>\n",
       "      <th>level</th>\n",
       "      <th>visit</th>\n",
       "      <th>post_date</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[카풀요청] 9/30(수) 서울 -&gt; 양양 죽도 카풀요청합니다</td>\n",
       "      <td>계란말이케챱 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>106</td>\n",
       "      <td>2020.09.25. 02:46</td>\n",
       "      <td>​친구녀석 대신 글올립니다 ㅠ날짜를 다르게 따로따로 가게되었거든요...​뭇튼, 강남...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[카풀요청] 9/26(토) 양양(죽도)&gt;&gt;&gt;시흥웨이브파크(혹은 서울)오전출발차 구합니다!</td>\n",
       "      <td>최윤선 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>1,985</td>\n",
       "      <td>2020.09.24. 22:36</td>\n",
       "      <td>동호회 카플 가이드: http://cafe.naver.com/surfx/23647(...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[카풀제공] 9월 26일 토요일 강릉,양양-경기,서울 복귀 편도 카풀제공</td>\n",
       "      <td>몽상가들 안양</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>194</td>\n",
       "      <td>2020.09.24. 18:56</td>\n",
       "      <td>이번 주 토요일 양양에서 복귀편 카풀제공합니다 보드캐리 불가이구요 강릉이나 양양에서...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[카풀제공] 9/26(토)~9/26(토) 서울 서울대입구역 주변 &lt;-&gt; 만리포 (당...</td>\n",
       "      <td>재훈 SEOUL</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>543</td>\n",
       "      <td>2020.09.24. 17:36</td>\n",
       "      <td>●목적지: 서울대입구역 주변 &lt;-&gt; 만리포 (편도가능)●서울출발장소: 서울대입구역 ...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[카풀요청] 9/29 화요일 서울역-&gt;양양 카풀구해요!</td>\n",
       "      <td>에이미a 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>1,010</td>\n",
       "      <td>2020.09.24. 16:23</td>\n",
       "      <td>화요일 아침 7시이후 카풀요청드립니다!목적지는 죽도구요 흡연상관없고 보드없고 짐가방...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[카풀제공] 9/25(금) 부천 -&gt; 양양 죽도 -&gt; 고성 편도 카풀 제공합니다. ...</td>\n",
       "      <td>물개 부천</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>1,978</td>\n",
       "      <td>2020.09.24. 16:14</td>\n",
       "      <td>●언제: 9/25일 금요일 오전 6시 출발●목적지: 고성●만나는 장소와 시간: 부천...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[카풀제공] 9/25일(금) 저녁 서울 → 양양 카풀제공합니다.</td>\n",
       "      <td>서대원 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>66</td>\n",
       "      <td>2020.09.24. 15:34</td>\n",
       "      <td>●언제: 9/25일 금요일 오후 6시 출발 (서울 강서구 마곡나루역)●목적지: 양양...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[카풀제공] 9/26(토)저녁 7시이후 출발 강남 양재역→ 양양일대 ,주문진,강릉</td>\n",
       "      <td>공룡발 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>2,493</td>\n",
       "      <td>2020.09.24. 13:46</td>\n",
       "      <td>카플 가이드: http://cafe.naver.com/surfx/23647(위 가이...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[카풀요청] 금진해변 -&gt;  서울 강서구 화곡동 보드만 캐리해 주실분~~</td>\n",
       "      <td>리쉬 서울 화곡</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>4,501</td>\n",
       "      <td>2020.09.24. 13:33</td>\n",
       "      <td>금진해변 -&gt; 서울 강서구 화곡동 보드만 캐리해 주실분~~사례비는 얼마인지 몰라서 ...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[카풀제공] 9/24(목)~9/26(토) 서울-양양</td>\n",
       "      <td>퉁췍 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>361</td>\n",
       "      <td>2020.09.24. 13:08</td>\n",
       "      <td>목요일 2시 신대방 출발토요일 2시 양양 출발​경로상 픽업 가능비흡연안전 주행​공일...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[카풀제공] 마감</td>\n",
       "      <td>쭌 서울시</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>394</td>\n",
       "      <td>2020.09.24. 12:42</td>\n",
       "      <td>월요일 오전(시간협의)중랑구 광진구 강동구등 서울 동부,경기 구리 하남편도 1.5 ...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[카풀요청] 9/28(월) 아침 서울 -&gt; 양양 카풀요청드립니다</td>\n",
       "      <td>계란말이케챱 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>106</td>\n",
       "      <td>2020.09.24. 11:59</td>\n",
       "      <td>안녕하세요.드뎌 등업되어 카풀요청 처음드려봅니다28일 월요일 아침에 양양가시는분 계...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[카풀제공] 25일(금)저녁 서울 → 양양 카풀 제공합니다.</td>\n",
       "      <td>버니타이거 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>3,814</td>\n",
       "      <td>2020.09.24. 09:40</td>\n",
       "      <td>※동호회 카플 가이드: http://cafe.naver.com/surfx/23647...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[카풀제공] 9/25(금) 가산(영등포,강남,잠실)-&gt;양양 카풀제공 합니다</td>\n",
       "      <td>까칠한 부천</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>1,234</td>\n",
       "      <td>2020.09.24. 09:20</td>\n",
       "      <td>●언제: 9/25(금) 가산디지털단지(영등포,강남,잠실등)-&gt;양양●목적지: 죽도(기...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[카풀요청] 25일 금요일 새벽아침 서울&gt;양양출발 구합니다!</td>\n",
       "      <td>제이비0707 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>254</td>\n",
       "      <td>2020.09.24. 09:07</td>\n",
       "      <td>서울 &gt; 기사문해변 도착이구​아침일찍이나 아침에 출발 하는 카풀 찾고 있습니다!편하...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[카풀제공]9월24일  양양오전==&gt;서울도착</td>\n",
       "      <td>염서퍼</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>2,582</td>\n",
       "      <td>2020.09.24. 08:51</td>\n",
       "      <td>☆올때☆●언제: 9월 24일 목요일오후12시그이후는 근무로 인해 불가능●만나는 장소...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[카풀제공] (제공,재업)  9월26일 토 수원일대  -&gt;  양양일대</td>\n",
       "      <td>물닭 수원</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>250</td>\n",
       "      <td>2020.09.24. 08:40</td>\n",
       "      <td>●언제: 9/26(토) 오전 9시출발 (조율가능하니 연락주세용)●목적지: 양양일대●...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[카풀요청] 내일 목요일 서울에서 죽도 당일치기 카풀요청드립니다</td>\n",
       "      <td>짱구 경기</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>6,744</td>\n",
       "      <td>2020.09.23. 23:58</td>\n",
       "      <td>새벽이나 아침출발 너무늦지않는 저녁복귀 당일치기 차량 있으면 구해봅니다 왕복으로​과...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[카풀제공] 9월24일(죽도) 목요일 건대,잠실 오전출발(협의가능-편도)</td>\n",
       "      <td>78허재성</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>161</td>\n",
       "      <td>2020.09.23. 20:21</td>\n",
       "      <td>죽도들렸다, 고성갑니다.근방(하조대,기사문) 하차해드립니다3명까지 카풀 가능합니다....</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>내일 이른 아침 서울&gt; 양양행 출발합니다</td>\n",
       "      <td>알파카 서울강동</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>3,558</td>\n",
       "      <td>2020.09.23. 19:12</td>\n",
       "      <td>​오늘 아침 7시~8시 강동&gt;양양​강동구 천호역찍고 설악~낙산주변 스팟드랍 선호합니...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title        nick  level  \\\n",
       "0                  [카풀요청] 9/30(수) 서울 -> 양양 죽도 카풀요청합니다   계란말이케챱 서울  새내기써퍼   \n",
       "1   [카풀요청] 9/26(토) 양양(죽도)>>>시흥웨이브파크(혹은 서울)오전출발차 구합니다!      최윤선 서울  새내기써퍼   \n",
       "2            [카풀제공] 9월 26일 토요일 강릉,양양-경기,서울 복귀 편도 카풀제공     몽상가들 안양  새내기써퍼   \n",
       "3   [카풀제공] 9/26(토)~9/26(토) 서울 서울대입구역 주변 <-> 만리포 (당...    재훈 SEOUL  새내기써퍼   \n",
       "4                      [카풀요청] 9/29 화요일 서울역->양양 카풀구해요!     에이미a 서울  새내기써퍼   \n",
       "5   [카풀제공] 9/25(금) 부천 -> 양양 죽도 -> 고성 편도 카풀 제공합니다. ...       물개 부천  새내기써퍼   \n",
       "6                 [카풀제공] 9/25일(금) 저녁 서울 → 양양 카풀제공합니다.      서대원 서울  새내기써퍼   \n",
       "7       [카풀제공] 9/26(토)저녁 7시이후 출발 강남 양재역→ 양양일대 ,주문진,강릉      공룡발 서울  새내기써퍼   \n",
       "8            [카풀요청] 금진해변 ->  서울 강서구 화곡동 보드만 캐리해 주실분~~    리쉬 서울 화곡  새내기써퍼   \n",
       "9                        [카풀제공] 9/24(목)~9/26(토) 서울-양양       퉁췍 서울  새내기써퍼   \n",
       "10                                          [카풀제공] 마감       쭌 서울시  새내기써퍼   \n",
       "11                [카풀요청] 9/28(월) 아침 서울 -> 양양 카풀요청드립니다   계란말이케챱 서울  새내기써퍼   \n",
       "12                  [카풀제공] 25일(금)저녁 서울 → 양양 카풀 제공합니다.    버니타이거 서울  새내기써퍼   \n",
       "13          [카풀제공] 9/25(금) 가산(영등포,강남,잠실)->양양 카풀제공 합니다      까칠한 부천  새내기써퍼   \n",
       "14                  [카풀요청] 25일 금요일 새벽아침 서울>양양출발 구합니다!  제이비0707 서울  새내기써퍼   \n",
       "15                           [카풀제공]9월24일  양양오전==>서울도착         염서퍼  새내기써퍼   \n",
       "16             [카풀제공] (제공,재업)  9월26일 토 수원일대  ->  양양일대       물닭 수원  새내기써퍼   \n",
       "17                [카풀요청] 내일 목요일 서울에서 죽도 당일치기 카풀요청드립니다       짱구 경기  새내기써퍼   \n",
       "18           [카풀제공] 9월24일(죽도) 목요일 건대,잠실 오전출발(협의가능-편도)       78허재성  새내기써퍼   \n",
       "19                             내일 이른 아침 서울> 양양행 출발합니다    알파카 서울강동  새내기써퍼   \n",
       "\n",
       "    visit          post_date  \\\n",
       "0     106  2020.09.25. 02:46   \n",
       "1   1,985  2020.09.24. 22:36   \n",
       "2     194  2020.09.24. 18:56   \n",
       "3     543  2020.09.24. 17:36   \n",
       "4   1,010  2020.09.24. 16:23   \n",
       "5   1,978  2020.09.24. 16:14   \n",
       "6      66  2020.09.24. 15:34   \n",
       "7   2,493  2020.09.24. 13:46   \n",
       "8   4,501  2020.09.24. 13:33   \n",
       "9     361  2020.09.24. 13:08   \n",
       "10    394  2020.09.24. 12:42   \n",
       "11    106  2020.09.24. 11:59   \n",
       "12  3,814  2020.09.24. 09:40   \n",
       "13  1,234  2020.09.24. 09:20   \n",
       "14    254  2020.09.24. 09:07   \n",
       "15  2,582  2020.09.24. 08:51   \n",
       "16    250  2020.09.24. 08:40   \n",
       "17  6,744  2020.09.23. 23:58   \n",
       "18    161  2020.09.23. 20:21   \n",
       "19  3,558  2020.09.23. 19:12   \n",
       "\n",
       "                                              content  \\\n",
       "0   ​친구녀석 대신 글올립니다 ㅠ날짜를 다르게 따로따로 가게되었거든요...​뭇튼, 강남...   \n",
       "1   동호회 카플 가이드: http://cafe.naver.com/surfx/23647(...   \n",
       "2   이번 주 토요일 양양에서 복귀편 카풀제공합니다 보드캐리 불가이구요 강릉이나 양양에서...   \n",
       "3   ●목적지: 서울대입구역 주변 <-> 만리포 (편도가능)●서울출발장소: 서울대입구역 ...   \n",
       "4   화요일 아침 7시이후 카풀요청드립니다!목적지는 죽도구요 흡연상관없고 보드없고 짐가방...   \n",
       "5   ●언제: 9/25일 금요일 오전 6시 출발●목적지: 고성●만나는 장소와 시간: 부천...   \n",
       "6   ●언제: 9/25일 금요일 오후 6시 출발 (서울 강서구 마곡나루역)●목적지: 양양...   \n",
       "7   카플 가이드: http://cafe.naver.com/surfx/23647(위 가이...   \n",
       "8   금진해변 -> 서울 강서구 화곡동 보드만 캐리해 주실분~~사례비는 얼마인지 몰라서 ...   \n",
       "9   목요일 2시 신대방 출발토요일 2시 양양 출발​경로상 픽업 가능비흡연안전 주행​공일...   \n",
       "10  월요일 오전(시간협의)중랑구 광진구 강동구등 서울 동부,경기 구리 하남편도 1.5 ...   \n",
       "11  안녕하세요.드뎌 등업되어 카풀요청 처음드려봅니다28일 월요일 아침에 양양가시는분 계...   \n",
       "12  ※동호회 카플 가이드: http://cafe.naver.com/surfx/23647...   \n",
       "13  ●언제: 9/25(금) 가산디지털단지(영등포,강남,잠실등)->양양●목적지: 죽도(기...   \n",
       "14  서울 > 기사문해변 도착이구​아침일찍이나 아침에 출발 하는 카풀 찾고 있습니다!편하...   \n",
       "15  ☆올때☆●언제: 9월 24일 목요일오후12시그이후는 근무로 인해 불가능●만나는 장소...   \n",
       "16  ●언제: 9/26(토) 오전 9시출발 (조율가능하니 연락주세용)●목적지: 양양일대●...   \n",
       "17  새벽이나 아침출발 너무늦지않는 저녁복귀 당일치기 차량 있으면 구해봅니다 왕복으로​과...   \n",
       "18  죽도들렸다, 고성갑니다.근방(하조대,기사문) 하차해드립니다3명까지 카풀 가능합니다....   \n",
       "19  ​오늘 아침 7시~8시 강동>양양​강동구 천호역찍고 설악~낙산주변 스팟드랍 선호합니...   \n",
       "\n",
       "                                                 link  \n",
       "0   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "1   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "2   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "3   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "4   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "5   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "6   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "7   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "8   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "9   https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "10  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "11  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "12  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "13  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "14  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "15  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "16  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "17  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "18  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "19  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('surfx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>nick</th>\n",
       "      <th>level</th>\n",
       "      <th>visit</th>\n",
       "      <th>post_date</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[카풀제공] 9/25(금) 부천 -&gt; 양양 죽도 -&gt; 고성 편도 카풀 제공합니다. ...</td>\n",
       "      <td>물개 부천</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>1,978</td>\n",
       "      <td>2020.09.24. 16:14</td>\n",
       "      <td>●언제: 9/25일 금요일 오전 6시 출발●목적지: 고성●만나는 장소와 시간: 부천...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[카풀제공] 9/25일(금) 저녁 서울 → 양양 카풀제공합니다.</td>\n",
       "      <td>서대원 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>66</td>\n",
       "      <td>2020.09.24. 15:34</td>\n",
       "      <td>●언제: 9/25일 금요일 오후 6시 출발 (서울 강서구 마곡나루역)●목적지: 양양...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[카풀제공] 25일(금)저녁 서울 → 양양 카풀 제공합니다.</td>\n",
       "      <td>버니타이거 서울</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>3,814</td>\n",
       "      <td>2020.09.24. 09:40</td>\n",
       "      <td>※동호회 카플 가이드: http://cafe.naver.com/surfx/23647...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[카풀제공] 9/25(금) 가산(영등포,강남,잠실)-&gt;양양 카풀제공 합니다</td>\n",
       "      <td>까칠한 부천</td>\n",
       "      <td>새내기써퍼</td>\n",
       "      <td>1,234</td>\n",
       "      <td>2020.09.24. 09:20</td>\n",
       "      <td>●언제: 9/25(금) 가산디지털단지(영등포,강남,잠실등)-&gt;양양●목적지: 죽도(기...</td>\n",
       "      <td>https://m.cafe.naver.com/ArticleRead.nhn?clubi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      nick  level  visit  \\\n",
       "0  [카풀제공] 9/25(금) 부천 -> 양양 죽도 -> 고성 편도 카풀 제공합니다. ...     물개 부천  새내기써퍼  1,978   \n",
       "1                [카풀제공] 9/25일(금) 저녁 서울 → 양양 카풀제공합니다.    서대원 서울  새내기써퍼     66   \n",
       "2                  [카풀제공] 25일(금)저녁 서울 → 양양 카풀 제공합니다.  버니타이거 서울  새내기써퍼  3,814   \n",
       "3          [카풀제공] 9/25(금) 가산(영등포,강남,잠실)->양양 카풀제공 합니다    까칠한 부천  새내기써퍼  1,234   \n",
       "\n",
       "           post_date                                            content  \\\n",
       "0  2020.09.24. 16:14  ●언제: 9/25일 금요일 오전 6시 출발●목적지: 고성●만나는 장소와 시간: 부천...   \n",
       "1  2020.09.24. 15:34  ●언제: 9/25일 금요일 오후 6시 출발 (서울 강서구 마곡나루역)●목적지: 양양...   \n",
       "2  2020.09.24. 09:40  ※동호회 카플 가이드: http://cafe.naver.com/surfx/23647...   \n",
       "3  2020.09.24. 09:20  ●언제: 9/25(금) 가산디지털단지(영등포,강남,잠실등)->양양●목적지: 죽도(기...   \n",
       "\n",
       "                                                link  \n",
       "0  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "1  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "2  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  \n",
       "3  https://m.cafe.naver.com/ArticleRead.nhn?clubi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜별 카풀 정보 찾기\n",
    "surfx.get_carpool(200925)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 패키지 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: surfing 0.0.1\n",
      "Uninstalling surfing-0.0.1:\n",
      "  Successfully uninstalled surfing-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y surfing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep sur"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
